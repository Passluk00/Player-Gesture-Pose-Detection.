{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c5c065a",
   "metadata": {},
   "source": [
    "# Player Gesture / Pose Detection\n",
    "\n",
    "This notebook implements a pipeline to detect human poses in images\n",
    "and classify player gestures using pre-trained pose estimation\n",
    "(keypoints) and a lightweight CNN/MLP.\n",
    "\n",
    "The workflow demonstrates GPU acceleration, reproducible pipelines,\n",
    "and computer vision skills relevant for game analytics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba3e8736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import Complete\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "from src.dataset import PoseDataset\n",
    "from src.model import PoseMLP\n",
    "from src.train import train_model\n",
    "from src.evaluate import evaluate_model\n",
    "from src.utils import save_model\n",
    "\n",
    "print(\"Import Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31736634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "DATA_IMAGE_DIR = \"../data/raw/images/\"\n",
    "ANNOTATION_FILE = \"../data/raw/cctvAnnotations.json\"\n",
    "\n",
    "CLASS_NAMES = [\"stand\", \"sit\", \"raise_hand\"]\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fcdf1e",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27d54e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded 933 valid samples\n",
      "Dataset size: 933\n"
     ]
    }
   ],
   "source": [
    "transform = T.Compose([\n",
    "    T.Resize((224,224)),\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = PoseDataset(\n",
    "    image_dir=DATA_IMAGE_DIR,\n",
    "    annotation_file=ANNOTATION_FILE,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "print(\"Dataset size:\", len(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "701aae22",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(len(dataset)))\n",
    "train_idx, val_idx = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "train_ds = Subset(dataset, train_idx)\n",
    "val_ds = Subset(dataset, val_idx)\n",
    "\n",
    "train_labels = [label.item() for _, label in train_ds]\n",
    "class_counts = Counter(train_labels)\n",
    "weights = [1.0 / class_counts[label] for label in train_labels]\n",
    "\n",
    "sampler = WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ca1252",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dadccad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = dataset[0][0].shape[0]\n",
    "\n",
    "model = PoseMLP(\n",
    "    input_dim=INPUT_DIM,\n",
    "    num_classes=NUM_CLASSES\n",
    ")\n",
    "\n",
    "class_weights = torch.tensor([1.0 / class_counts.get(i,1) for i in range(NUM_CLASSES)], device=device)\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be90d9f5",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba09c11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:07<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25] | Loss: 24.2435 | Val Acc: 0.7647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:07<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/25] | Loss: 10.4858 | Val Acc: 0.4706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:07<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/25] | Loss: 8.8116 | Val Acc: 0.5829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:07<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/25] | Loss: 12.5730 | Val Acc: 0.9519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:07<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/25] | Loss: 8.0376 | Val Acc: 0.8984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:07<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/25] | Loss: 5.4872 | Val Acc: 0.7540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:07<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/25] | Loss: 2.8660 | Val Acc: 0.9412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:07<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/25] | Loss: 2.2662 | Val Acc: 0.7807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:07<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/25] | Loss: 1.8525 | Val Acc: 0.9572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:07<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/25] | Loss: 1.7278 | Val Acc: 0.8503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:07<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/25] | Loss: 0.8917 | Val Acc: 0.9572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:07<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/25] | Loss: 0.8048 | Val Acc: 0.9465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:07<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/25] | Loss: 1.2757 | Val Acc: 0.9091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:07<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/25] | Loss: 2.5461 | Val Acc: 0.9091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:07<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/25] | Loss: 1.4122 | Val Acc: 0.9572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:07<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/25] | Loss: 1.6910 | Val Acc: 0.8824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:07<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/25] | Loss: 0.9562 | Val Acc: 0.7914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:07<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/25] | Loss: 1.1242 | Val Acc: 0.9572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:07<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/25] | Loss: 1.0243 | Val Acc: 0.9412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:08<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/25] | Loss: 1.5959 | Val Acc: 0.9144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:07<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/25] | Loss: 1.1480 | Val Acc: 0.9144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:07<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/25] | Loss: 3.6915 | Val Acc: 0.9305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:07<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/25] | Loss: 2.1185 | Val Acc: 0.8503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:07<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/25] | Loss: 1.6851 | Val Acc: 0.9412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:07<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/25] | Loss: 3.2677 | Val Acc: 0.7594\n"
     ]
    }
   ],
   "source": [
    "model = train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device,\n",
    "    epochs=25\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65701e9e",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e4a1e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       stand       0.00      0.00      0.00         0\n",
      "         sit       1.00      0.75      0.85       177\n",
      "  raise_hand       0.18      1.00      0.31        10\n",
      "\n",
      "    accuracy                           0.76       187\n",
      "   macro avg       0.39      0.58      0.39       187\n",
      "weighted avg       0.96      0.76      0.83       187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, val_loader, device, CLASS_NAMES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1d34e0",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87e456e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Model saved to ../outputs/models/pose_mlp.pth\n"
     ]
    }
   ],
   "source": [
    "save_model(model, \"../outputs/models/pose_mlp.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_pose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
